<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Problem 4: Sports OR Politics</title>
    <style>
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            line-height: 1.6;
            color: #333;
            max-width: 900px;
            margin: 0 auto;
            padding: 40px 20px;
            background-color: #f9f9f9;
        }

        .container {
            background: #fff;
            padding: 40px;
            border-radius: 8px;
            box-shadow: 0 4px 15px rgba(0, 0, 0, 0.05);
        }

        h1 {
            color: #2c3e50;
            border-bottom: 3px solid #3498db;
            padding-bottom: 15px;
            margin-bottom: 30px;
        }

        h2 {
            color: #2c3e50;
            margin-top: 40px;
            border-left: 5px solid #3498db;
            padding-left: 15px;
        }

        h3 {
            color: #34495e;
            margin-top: 25px;
        }

        p {
            margin-bottom: 15px;
            text-align: justify;
        }

        /* Image Styling */
        img {
            max-width: 100%;
            height: auto;
            border: 1px solid #ddd;
            box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
            margin: 20px 0;
            border-radius: 4px;
        }

        .img-caption {
            text-align: center;
            font-size: 0.9em;
            color: #7f8c8d;
            margin-top: -15px;
            margin-bottom: 25px;
            font-style: italic;
        }

        .flex-images {
            display: flex;
            gap: 20px;
            flex-wrap: wrap;
            justify-content: center;
        }

        .flex-images>div {
            flex: 1;
            min-width: 300px;
        }

        /* Table Styling */
        table {
            width: 100%;
            border-collapse: collapse;
            margin: 25px 0;
            box-shadow: 0 1px 3px rgba(0, 0, 0, 0.1);
        }

        th,
        td {
            padding: 12px 15px;
            border: 1px solid #eee;
            text-align: left;
        }

        th {
            background-color: #3498db;
            color: white;
            font-weight: 600;
        }

        tr:nth-child(even) {
            background-color: #f8f9fa;
        }

        tr:hover {
            background-color: #f1f1f1;
        }

        /* Highlights */
        .highlight-box {
            background-color: #e8f4fd;
            border-left: 5px solid #3498db;
            padding: 15px 20px;
            margin: 20px 0;
            border-radius: 0 5px 5px 0;
        }

        .error-box {
            background-color: #fdedec;
            border-left: 5px solid #e74c3c;
            padding: 15px 20px;
            margin: 20px 0;
            border-radius: 0 5px 5px 0;
        }

        .meta {
            color: #7f8c8d;
            font-size: 1.1em;
            margin-bottom: 40px;
        }
    </style>
</head>

<body>
    <div class="container">
        <h1>Problem 4: Sports OR Politics</h1>
        <div class="meta">
            <strong>Name:</strong> Shubham Haraniya<br>
            <strong>Roll No:</strong> M25CSA013<br>
            <strong>Subject:</strong> Natural Language Understanding - Assignment 1
        </div>

        <h2>1. Introduction</h2>
        <p>In the age of digital information, automating the organization of text is crucial. This detailed report
            presents the design and evaluation of a machine learning classifier capable of distinguishing between
            <strong>Sports</strong> and <strong>Politics</strong> documents.</p>
        <p>Using the 20 Newsgroups dataset, we explore the efficacy of simple probability-based models against more
            complex geometric models. The results are surprising: the simplest approach often yields the best
            performance when the vocabularies are distinct.</p>

        <h2>2. Data Collection and Exploration</h2>
        <p>We curated a balanced subset from the 20 Newsgroups benchmark:</p>
        <ul>
            <li><strong>Sports:</strong> Baseball and Hockey discussions (<code>rec.sport.*</code>)</li>
            <li><strong>Politics:</strong> Gun control, Mideast, and general politics (<code>talk.politics.*</code>)
            </li>
        </ul>

        <h3>Class Distribution</h3>
        <p>Before training, we verified that the dataset is reasonably balanced to prevent model bias.</p>
        <img src="images/class_distribution.png" alt="Class Distribution Chart">
        <div class="img-caption">Figure 1: Distribution of documents in the Train Set.</div>

        <h3>Vocabulary Analysis</h3>
        <p>What distinguishes these topics? By analyzing the top 20 most frequent words, we see a clear separation.
            Sports documents are dominated by "game", "team", and "play", while Politics documents focus on
            "government", "people", and "rights".</p>

        <div class="flex-images">
            <div>
                <img src="images/top_words_sports.png" alt="Top Words in Sports">
                <div class="img-caption">Figure 2a: Top 20 Words in Sports</div>
            </div>
            <div>
                <img src="images/top_words_politics.png" alt="Top Words in Politics">
                <div class="img-caption">Figure 2b: Top 20 Words in Politics</div>
            </div>
        </div>

        <h2>3. Methodology</h2>
        <p>Our implementation pipeline consists of three stages:</p>
        <ol>
            <li><strong>Preprocessing:</strong> Converting text to lowercase and removing English stop words (common
                words like "the", "is" that carry no meaning).</li>
            <li><strong>Feature Extraction:</strong>
                <ul>
                    <li><strong>Bag of Words (BoW):</strong> Simple word counts.</li>
                    <li><strong>TF-IDF:</strong> Weighted scores that penalize common words.</li>
                    <li><strong>N-grams (1,2):</strong> Using pairs of words (Bigrams) to capture context.</li>
                </ul>
            </li>
            <li><strong>Modeling:</strong> Training Naive Bayes, Support Vector Machines (SVM), and Logistic Regression.
            </li>
        </ol>

        <h2>4. Experimental Results</h2>
        <p>We conducted extensive experiments across all combinations of features and models. The quantitative results
            are summarized below.</p>

        <table>
            <thead>
                <tr>
                    <th>Feature Representation</th>
                    <th>Model Algorithm</th>
                    <th>Accuracy</th>
                    <th>F1-Score</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td><strong>Bag of Words</strong></td>
                    <td><strong>Naive Bayes</strong></td>
                    <td><strong>99.24%</strong></td>
                    <td><strong>0.99</strong></td>
                </tr>
                <tr>
                    <td>Bag of Words</td>
                    <td>SVM</td>
                    <td>97.07%</td>
                    <td>0.97</td>
                </tr>
                <tr>
                    <td>Bag of Words</td>
                    <td>Logistic Regression</td>
                    <td>97.56%</td>
                    <td>0.98</td>
                </tr>
                <tr>
                    <td>TF-IDF</td>
                    <td>Naive Bayes</td>
                    <td>98.43%</td>
                    <td>0.98</td>
                </tr>
                <tr>
                    <td>TF-IDF</td>
                    <td>SVM</td>
                    <td>98.92%</td>
                    <td>0.99</td>
                </tr>
                <tr>
                    <td>TF-IDF</td>
                    <td>Logistic Regression</td>
                    <td>98.54%</td>
                    <td>0.99</td>
                </tr>
                <tr>
                    <td>N-grams (1,2)</td>
                    <td>Naive Bayes</td>
                    <td>96.91%</td>
                    <td>0.97</td>
                </tr>
                <tr>
                    <td>N-grams (1,2)</td>
                    <td>SVM</td>
                    <td>98.70%</td>
                    <td>0.99</td>
                </tr>
                <tr>
                    <td>N-grams (1,2)</td>
                    <td>Logistic Regression</td>
                    <td>98.43%</td>
                    <td>0.98</td>
                </tr>
            </tbody>
        </table>

        <div class="highlight-box">
            <h3>Key Insight: Simplicity Wins</h3>
            <p>The <strong>Naive Bayes + Bag of Words</strong> model achieved the highest accuracy of 99.24%. This
                confirms that for topically distinct categories, the simple presence of keywords is a stronger signal
                than complex geometric boundaries.</p>
        </div>

        <h3>Visual Comparison</h3>
        <img src="images/model_comparison.png" alt="Model Comparison Graph">
        <div class="img-caption">Figure 3: Comparative accuracy of all trained models.</div>

        <h2>5. Analysis & Discussion</h2>

        <h3>The "N-gram Paradox"</h3>
        <p>We hypothesized that adding Bigrams (pairs of words) would improve accuracy. However, results show that
            enabling N-grams actually <strong>reduced</strong> performance for Naive Bayes (99.24% &rarr; 96.91%). This
            is due to <strong>data sparsity</strong>: adding bigrams explodes the feature space to hundreds of thousands
            of features, making it harder for the model to generalize from a small training set (~2800 docs).</p>

        <h3>Error Analysis</h3>
        <p>The confusion matrix for our best model shows near-perfect performance.</p>
        <img src="images/confusion_matrix_best.png" alt="Confusion Matrix">
        <div class="img-caption">Figure 4: Confusion Matrix for Naive Bayes.</div>

        <div class="error-box">
            <strong>Where did it fail?</strong><br>
            Manual inspection revealed that the few misclassifications were often due to <strong>metaphors</strong>. For
            example, a Politics article discussing a "political football" or a "home run for the administration"
            contains sports vocabulary that tricks the model.
        </div>

        <h2>6. Conclusion</h2>
        <p>This study demonstrates that text classification does not always require massive neural networks. For
            distinct domains like Sports and Politics, classical Naive Bayes is extremely effective, fast, and
            explainable. We achieved >99% accuracy with minimal computational cost, validating the power of fundamental
            NLP techniques.</p>

        <hr style="margin: 40px 0; border: 0; border-top: 1px solid #eee;">
        <p style="text-align: center; color: #999;">&copy; 2026 Shubham Haraniya. All rights reserved.</p>
    </div>
</body>


</html>

